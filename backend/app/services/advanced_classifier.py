# backend/app/services/advanced_classifier.py
import pandas as pd
import pickle
import numpy as np
import re
import time
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import RSLPStemmer

logger = logging.getLogger(__name__)

class AdvancedEmailClassifier:
    """
    Classificador avanÃ§ado de emails para o projeto AutoU
    """
    
    def __init__(self, model_path: str = "../app/services/advanced_model.pkl"):
        self.model_path = model_path
        self.model = None
        self.vectorizer = None
        self.scaler = None
        self.stemmer = RSLPStemmer()
        
        # Palavras-chave otimizadas para contexto empresarial
        self.productive_keywords = {
            'erro', 'bug', 'falha', 'problema', 'defeito', 'crash',
            'nÃ£o funciona', 'quebrado', 'parou', 'travou', 'lento',
            'preciso', 'solicito', 'gostaria', 'como fazer', 'ajuda',
            'suporte', 'orientaÃ§Ã£o', 'instruÃ§Ã£o', 'tutorial',
            'urgente', 'crÃ­tico', 'importante', 'prioritÃ¡rio', 'asap',
            'deadline', 'prazo', 'vencimento',
            'configuraÃ§Ã£o', 'instalaÃ§Ã£o', 'setup', 'integraÃ§Ã£o',
            'api', 'sistema', 'plataforma', 'aplicativo', 'software',
            'login', 'senha', 'acesso', 'bloqueado', 'desabilitado',
            'permissÃ£o', 'autenticaÃ§Ã£o', 'conta',
            'pagamento', 'cobranÃ§a', 'fatura', 'contrato', 'renovaÃ§Ã£o',
            'cancelamento', 'reembolso', 'upgrade', 'downgrade',
            'status', 'andamento', 'protocolo', 'nÃºmero', 'cÃ³digo',
            'relatÃ³rio', 'dados', 'informaÃ§Ãµes', 'detalhes'
        }
        
        self.unproductive_keywords = {
            'obrigado', 'obrigada', 'agradeÃ§o', 'agradecimento',
            'gratidÃ£o', 'grato', 'grata', 'reconhecido',
            'parabÃ©ns', 'felicitaÃ§Ãµes', 'congratulaÃ§Ãµes',
            'sucesso', 'conquista', 'vitÃ³ria', 'prÃªmio',
            'aniversÃ¡rio', 'nascimento', 'casamento', 'formatura',
            'festa', 'comemoraÃ§Ã£o', 'celebraÃ§Ã£o',
            'natal', 'ano novo', 'pÃ¡scoa', 'feriado', 'fÃ©rias',
            'final de semana', 'descanso',
            'cumprimentos', 'saudaÃ§Ãµes', 'abraÃ§os', 'beijos',
            'tenha um bom dia', 'boa sorte', 'tudo de bom',
            'famÃ­lia', 'saÃºde', 'melhoras', 'cuidados',
            'felicidade', 'alegria', 'paz'
        }
        
        self._download_nltk_resources()
        
        if self._model_exists():
            self._load_model()
    
    def _download_nltk_resources(self):
        """Baixa recursos necessÃ¡rios do NLTK"""
        resources = ['stopwords', 'punkt', 'rslp']
        for resource in resources:
            try:
                nltk.data.find(f'tokenizers/{resource}')
            except LookupError:
                try:
                    nltk.download(resource, quiet=True)
                except Exception as e:
                    logger.warning(f"NÃ£o foi possÃ­vel baixar {resource}: {e}")
    
    def _model_exists(self) -> bool:
        """Verifica se o modelo existe"""
        import os
        return os.path.exists(self.model_path)
    
    def _load_model(self):
        """Carrega modelo treinado"""
        try:
            with open(self.model_path, 'rb') as f:
                model_data = pickle.load(f)
                self.model = model_data['model']
                self.vectorizer = model_data['vectorizer']
                self.scaler = model_data.get('scaler')
            logger.info(f"âœ… Modelo avanÃ§ado carregado de {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ Erro ao carregar modelo: {e}")
            self.model = None
    
    def preprocess_text(self, text: str) -> str:
        """Preprocessa texto para anÃ¡lise"""
        if not text:
            return ""
        
        text = text.lower()
        text = re.sub(r'[^\w\s\?!.,;:]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        
        try:
            stopwords_pt = set(stopwords.words('portuguese'))
            tokens = word_tokenize(text, language='portuguese')
            
            processed_tokens = []
            for token in tokens:
                if (len(token) > 2 and 
                    (token not in stopwords_pt or 
                     token in self.productive_keywords or 
                     token in self.unproductive_keywords)):
                    
                    try:
                        stemmed = self.stemmer.stem(token)
                        processed_tokens.append(stemmed)
                    except:
                        processed_tokens.append(token)
            
            return ' '.join(processed_tokens)
            
        except Exception as e:
            logger.warning(f"Erro no processamento NLTK: {e}")
            return text
    
    def extract_features(self, text: str) -> Dict[str, float]:
        """Extrai caracterÃ­sticas avanÃ§adas do texto (19 features fixas)"""
        features = {}
        
        features['length'] = len(text)
        features['word_count'] = len(text.split())
        
        try:
            sentences = sent_tokenize(text, language='portuguese')
            features['sentence_count'] = len(sentences)
        except:
            features['sentence_count'] = text.count('.') + text.count('!') + text.count('?')
        
        words = text.split()
        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0
        
        features['question_marks'] = text.count('?')
        features['exclamation_marks'] = text.count('!')
        features['periods'] = text.count('.')
        features['commas'] = text.count(',')
        
        features['uppercase_ratio'] = sum(1 for c in text if c.isupper()) / len(text) if text else 0
        features['repeated_chars'] = len(re.findall(r'(.)\1{2,}', text))
        
        features['has_email'] = 1 if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text) else 0
        features['has_phone'] = 1 if re.search(r'\b\d{8,11}\b', text) else 0
        features['has_url'] = 1 if re.search(r'http[s]?://|www\.', text) else 0
        features['has_numbers'] = 1 if re.search(r'\d+', text) else 0
        features['has_time'] = 1 if re.search(r'\d{1,2}:\d{2}', text) else 0
        features['has_date'] = 1 if re.search(r'\d{1,2}/\d{1,2}', text) else 0
        
        text_lower = text.lower()
        productive_count = sum(1 for keyword in self.productive_keywords if keyword in text_lower)
        unproductive_count = sum(1 for keyword in self.unproductive_keywords if keyword in text_lower)
        
        features['productive_keywords'] = productive_count
        features['unproductive_keywords'] = unproductive_count
        features['keyword_ratio'] = productive_count / (unproductive_count + 1)
        
        return features
    
    def classify(self, content: str) -> Dict:
        """Classifica email e retorna resultado detalhado"""
        start_time = time.time()
        
        if not self.model:
            raise ValueError("Modelo nÃ£o foi carregado. Execute o treinamento primeiro.")
        
        try:
            processed_text = self.preprocess_text(content)
            features = self.extract_features(content)
            feature_array = np.array(list(features.values())).reshape(1, -1)
            
            text_vec = self.vectorizer.transform([processed_text])
            
            if self.scaler:
                feature_array = self.scaler.transform(feature_array)
            
            try:
                from scipy.sparse import hstack
                X_combined = hstack([text_vec, feature_array])
            except ImportError:
                X_combined = text_vec
            
            prediction = self.model.predict(X_combined)[0]
            probabilities = self.model.predict_proba(X_combined)[0]
            confidence = max(probabilities)
            
            suggested_response = self._generate_intelligent_response(prediction, content, features)
            
            processing_time = time.time() - start_time
            
            result = {
                'classification': prediction,
                'confidence': float(confidence),
                'probabilities': {
                    label: float(prob) for label, prob 
                    in zip(self.model.classes_, probabilities)
                },
                'suggested_response': suggested_response,
                'processing_time': processing_time,
                'features_detected': features,
                'text_length': len(content),
                'processed_text_length': len(processed_text)
            }
            
            logger.info(f"Email classificado como {prediction} (confianÃ§a: {confidence:.3f})")
            return result
            
        except Exception as e:
            logger.error(f"Erro na classificaÃ§Ã£o: {str(e)}")
            raise
    
    def train_model(self, dataset_path: str) -> Dict[str, float]:
        """Treina o modelo com dataset"""
        logger.info("Iniciando treinamento do modelo avanÃ§ado...")
        
        df = pd.read_csv(dataset_path)
        if 'text' not in df.columns or 'label' not in df.columns:
            raise ValueError("CSV deve conter colunas 'text' e 'label'")
        
        df['processed_text'] = df['text'].apply(self.preprocess_text)
        feature_dicts = df['processed_text'].apply(self.extract_features)
        feature_df = pd.DataFrame(feature_dicts.tolist())
        
        X_text = df['processed_text'].values
        X_features = feature_df.values
        y = df['label'].values
        
        X_text_train, X_text_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(
            X_text, X_features, y, test_size=0.2, random_state=42, stratify=y
        )
        
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.95,
            sublinear_tf=True
        )
        
        X_text_train_vec = self.vectorizer.fit_transform(X_text_train)
        X_text_test_vec = self.vectorizer.transform(X_text_test)
        
        self.scaler = StandardScaler()
        X_feat_train_scaled = self.scaler.fit_transform(X_feat_train)
        X_feat_test_scaled = self.scaler.transform(X_feat_test)
        
        from scipy.sparse import hstack
        X_train_combined = hstack([X_text_train_vec, X_feat_train_scaled])
        X_test_combined = hstack([X_text_test_vec, X_feat_test_scaled])
        
        self.model = RandomForestClassifier(
            n_estimators=200,
            max_depth=20,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train_combined, y_train)
        
        y_pred = self.model.predict(X_test_combined)
        accuracy = accuracy_score(y_test, y_pred)
        cv_scores = cross_val_score(self.model, X_train_combined, y_train, cv=5)
        
        model_data = {
            'model': self.model,
            'vectorizer': self.vectorizer,
            'scaler': self.scaler
        }
        
        with open(self.model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print("\n" + "="*50)
        print("ğŸ“Š RELATÃ“RIO DE TREINAMENTO")
        print("="*50)
        print(f"âœ… AcurÃ¡cia no teste: {accuracy:.3f}")
        print(f"âœ… Cross-validation mÃ©dia: {cv_scores.mean():.3f} (Â±{cv_scores.std()*2:.3f})")
        print("\nğŸ“‹ RelatÃ³rio de classificaÃ§Ã£o:")
        print(classification_report(y_test, y_pred))
        
        logger.info(f"Modelo treinado e salvo em {self.model_path}")
        
        return {
            'accuracy': accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std()
        }
    
    def _generate_intelligent_response(self, classification: str, content: str, features: Dict) -> str:
        """Gera resposta inteligente baseada na classificaÃ§Ã£o"""
        content_lower = content.lower()
        
        if classification == "PRODUTIVO":
            return self._generate_productive_response(content_lower, features)
        else:
            return self._generate_unproductive_response(content_lower, features)
    
    def _generate_productive_response(self, content: str, features: Dict) -> str:
        """Gera resposta especÃ­fica para emails produtivos"""
        
        if any(word in content for word in ['login', 'senha', 'acesso', 'autenticaÃ§Ã£o']):
            urgency = "ALTA" if features.get('exclamation_marks', 0) > 1 else "NORMAL"
            return f"""OlÃ¡!

Identificamos um problema de acesso em sua conta (Prioridade: {urgency}).

ğŸ”§ **SoluÃ§Ãµes rÃ¡pidas:**
â€¢ Verifique se estÃ¡ usando o email correto
â€¢ Use "Esqueci minha senha" para redefinir
â€¢ Limpe cache/cookies do navegador
â€¢ Desative bloqueadores temporariamente

ğŸ“ **Suporte imediato:**
â€¢ Chat online: DisponÃ­vel 24/7
â€¢ Email: suporte@empresa.com
â€¢ Telefone: (11) 1234-5678

Resolveremos com mÃ¡xima prioridade!

Atenciosamente,
Equipe de Suporte TÃ©cnico"""

        elif any(word in content for word in ['erro', 'bug', 'falha', 'problema']):
            return """OlÃ¡!

Recebemos seu reporte tÃ©cnico e nossa equipe jÃ¡ foi alertada.

ğŸš€ **Em andamento:**
â€¢ AnÃ¡lise detalhada do problema
â€¢ IdentificaÃ§Ã£o da causa raiz
â€¢ Desenvolvimento da soluÃ§Ã£o
â€¢ Testes de qualidade

â° **Prazos estimados:**
â€¢ Retorno inicial: 4 horas
â€¢ CorreÃ§Ã£o: 24-48 horas
â€¢ AtualizaÃ§Ãµes: A cada 6 horas

VocÃª receberÃ¡ notificaÃ§Ãµes automÃ¡ticas sobre o progresso.

Obrigado por nos ajudar a melhorar!

Equipe de Desenvolvimento"""

        elif any(word in content for word in ['status', 'andamento', 'protocolo']):
            return """Prezado(a),

Consultamos o status da sua solicitaÃ§Ã£o:

ğŸ“‹ **SituaÃ§Ã£o atual:**
â€¢ Protocolada e em anÃ¡lise
â€¢ Equipe especializada responsÃ¡vel
â€¢ Prioridade definida pelo conteÃºdo

ğŸ“… **Timeline:**
â€¢ AnÃ¡lise: 1-2 dias Ãºteis
â€¢ Processamento: 2-3 dias Ãºteis
â€¢ Resposta final: atÃ© 5 dias Ãºteis

ğŸ”” **Acompanhamento:**
AtualizaÃ§Ãµes automÃ¡ticas por email e portal online.

Cordialmente,
Central de Atendimento"""

        else:
            urgency = "ALTA" if features.get('question_marks', 0) > 2 or features.get('exclamation_marks', 0) > 2 else "NORMAL"
            return f"""Prezado(a),

Sua mensagem foi recebida e classificada (Prioridade: {urgency}).

âœ… **Status:**
â€¢ Registrada no sistema
â€¢ Equipe notificada
â€¢ Protocolo em geraÃ§Ã£o

âš¡ **PrÃ³ximos passos:**
â€¢ AnÃ¡lise: atÃ© 2 horas
â€¢ Retorno: atÃ© 6 horas
â€¢ ResoluÃ§Ã£o: 24-48 horas

Nossa equipe trabalharÃ¡ para resolver com mÃ¡xima eficiÃªncia.

Atenciosamente,
Equipe de Atendimento"""
    
    def _generate_unproductive_response(self, content: str, features: Dict) -> str:
        """Gera resposta especÃ­fica para emails improdutivos"""
        
        if any(word in content for word in ['parabÃ©ns', 'felicitaÃ§Ãµes', 'sucesso']):
            return """ğŸ‰ Que alegria receber sua mensagem!

Ficamos profundamente honrados com suas felicitaÃ§Ãµes. Ã‰ esse reconhecimento que nos motiva a superar expectativas diariamente.

Seu feedback serÃ¡ compartilhado com toda a equipe que contribui para nosso sucesso.

Muito obrigado por fazer parte da nossa jornada!

Com gratidÃ£o,
Toda a equipe ğŸ’™"""

        elif any(word in content for word in ['obrigado', 'obrigada', 'agradeÃ§o']):
            return """ğŸ˜Š Que mensagem maravilhosa!

Ã‰ uma satisfaÃ§Ã£o imensa saber que fizemos a diferenÃ§a. Momentos como este nos lembram do propÃ³sito do nosso trabalho.

Agradecemos por compartilhar sua experiÃªncia positiva conosco!

Sempre que precisar, estaremos aqui.

Com carinho,
Equipe de Atendimento âœ¨"""

        elif any(word in content for word in ['natal', 'ano novo', 'feriado']):
            return """ğŸŠ Que mensagem especial!

Agradecemos sua lembranÃ§a carinhosa. Desejamos momentos especiais ao lado de quem vocÃª ama.

Que venham muitas alegrias e conquistas!

Com carinho especial,
Toda nossa equipe ğŸŒŸ"""

        else:
            return """ğŸ’ Que presente receber sua mensagem!

Ficamos genuinamente emocionados. Ã‰ maravilhoso ter pessoas como vocÃª em nossa comunidade.

Sua mensagem trouxe sorrisos para todo nosso time.

Desejamos tudo de melhor!

Com muito apreÃ§o,
Equipe dedicada ğŸŒˆ"""